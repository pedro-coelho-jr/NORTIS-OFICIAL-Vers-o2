{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados combinados salvos em Estabelecimentos_Atualizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from Search.Search_Archives import encontrar_arquivo\n",
    "from Search.Search_Diretory import encontrar_diretorio\n",
    "\n",
    "# Caminho para o arquivo de estabelecimentos corrigidos\n",
    "estabelecimentos_path = encontrar_arquivo('Estabelecimentos.csv')\n",
    "estabelecimentos_df = pd.read_csv(estabelecimentos_path)\n",
    "\n",
    "feiras_path = encontrar_arquivo('Feiras Livres.xlsx')\n",
    "feiras_df = pd.read_excel(feiras_path)\n",
    "\n",
    "# Verificar colunas comuns e renomear, se necessário\n",
    "feiras_df = feiras_df[['id', 'Rede', 'Nome', 'Localizado em', 'Endereço', 'Bairro', 'CEP', 'Tipo', 'Latitude', 'Longitude']]\n",
    "\n",
    "# Concatenar os dados\n",
    "dados_combinados = pd.concat([estabelecimentos_df, feiras_df], ignore_index=True)\n",
    "\n",
    "# Salvar o arquivo atualizado\n",
    "output_path = \"Estabelecimentos.csv\"\n",
    "dados_combinados.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Dados combinados salvos em {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Nome</th>\n",
       "      <th>Localizado em</th>\n",
       "      <th>Endereço</th>\n",
       "      <th>Rede</th>\n",
       "      <th>Bairro</th>\n",
       "      <th>CEP</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FeiraLivre-c7925648</td>\n",
       "      <td>MANDAQUI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA GENERAL JOSE ALMEIDA BOTELHO S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.632993</td>\n",
       "      <td>-23.470371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FeiraLivre-e6a65fc8</td>\n",
       "      <td>SANTA INES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA ANA DE BARROS S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.631521</td>\n",
       "      <td>-23.469350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FeiraLivre-2150df96</td>\n",
       "      <td>SANTO ANTONIO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRACA  SALVADOR TOLEZANO S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.636865</td>\n",
       "      <td>-23.469879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FeiraLivre-47704bbf</td>\n",
       "      <td>JOAO PESSOA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA RIBEIRAO DO SALTO S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.650463</td>\n",
       "      <td>-23.479616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FeiraLivre-8e0188e2</td>\n",
       "      <td>HERISON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA HERISON S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.643746</td>\n",
       "      <td>-23.471913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>FeiraLivre-7c6edfc9</td>\n",
       "      <td>MORAES BARROS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA FIRMIANO PINTO S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.604611</td>\n",
       "      <td>-23.539130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>FeiraLivre-e9f4b267</td>\n",
       "      <td>PAULO ANDREGUETTI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA SILVA TELES1528</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.605397</td>\n",
       "      <td>-23.525259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>FeiraLivre-86e568df</td>\n",
       "      <td>BELEM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA IRMA CAROLINA S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.586221</td>\n",
       "      <td>-23.538563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>FeiraLivre-922b81a7</td>\n",
       "      <td>ITAMARACA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA SERRA DE JAIRE S/N</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.587749</td>\n",
       "      <td>-23.543724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>FeiraLivre-87d7bb99</td>\n",
       "      <td>IRMA CAROLINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RUA ENG REINALDO CAJADO215</td>\n",
       "      <td>SEM REDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Feira Livre</td>\n",
       "      <td>-46.582891</td>\n",
       "      <td>-23.536904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>945 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id               Nome  Localizado em  \\\n",
       "0    FeiraLivre-c7925648           MANDAQUI            NaN   \n",
       "1    FeiraLivre-e6a65fc8         SANTA INES            NaN   \n",
       "2    FeiraLivre-2150df96      SANTO ANTONIO            NaN   \n",
       "3    FeiraLivre-47704bbf        JOAO PESSOA            NaN   \n",
       "4    FeiraLivre-8e0188e2            HERISON            NaN   \n",
       "..                   ...                ...            ...   \n",
       "940  FeiraLivre-7c6edfc9      MORAES BARROS            NaN   \n",
       "941  FeiraLivre-e9f4b267  PAULO ANDREGUETTI            NaN   \n",
       "942  FeiraLivre-86e568df              BELEM            NaN   \n",
       "943  FeiraLivre-922b81a7          ITAMARACA            NaN   \n",
       "944  FeiraLivre-87d7bb99      IRMA CAROLINA            NaN   \n",
       "\n",
       "                                 Endereço      Rede  Bairro  CEP         Tipo  \\\n",
       "0    RUA GENERAL JOSE ALMEIDA BOTELHO S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "1                   RUA ANA DE BARROS S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "2            PRACA  SALVADOR TOLEZANO S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "3               RUA RIBEIRAO DO SALTO S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "4                         RUA HERISON S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "..                                    ...       ...     ...  ...          ...   \n",
       "940                RUA FIRMIANO PINTO S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "941                   RUA SILVA TELES1528  SEM REDE     NaN  NaN  Feira Livre   \n",
       "942                 RUA IRMA CAROLINA S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "943                RUA SERRA DE JAIRE S/N  SEM REDE     NaN  NaN  Feira Livre   \n",
       "944            RUA ENG REINALDO CAJADO215  SEM REDE     NaN  NaN  Feira Livre   \n",
       "\n",
       "     Longitude   Latitude  \n",
       "0   -46.632993 -23.470371  \n",
       "1   -46.631521 -23.469350  \n",
       "2   -46.636865 -23.469879  \n",
       "3   -46.650463 -23.479616  \n",
       "4   -46.643746 -23.471913  \n",
       "..         ...        ...  \n",
       "940 -46.604611 -23.539130  \n",
       "941 -46.605397 -23.525259  \n",
       "942 -46.586221 -23.538563  \n",
       "943 -46.587749 -23.543724  \n",
       "944 -46.582891 -23.536904  \n",
       "\n",
       "[945 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from Search.Search_Archives import encontrar_arquivo\n",
    "from Search.Search_Diretory import encontrar_diretorio\n",
    "\n",
    "# Caminho para o arquivo de estabelecimentos corrigidos\n",
    "estabelecimentos_path = encontrar_arquivo('Estabelecimentos.csv')\n",
    "estabelecimentos_df = pd.read_csv(estabelecimentos_path)\n",
    "\n",
    "feiras_path = encontrar_arquivo('Feiras Livres.xlsx')\n",
    "feiras_df = pd.read_excel(feiras_path)\n",
    "feiras_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estabelecimentos_path = encontrar_arquivo('Estabelecimentos.csv')\n",
    "estabelecimentos_df = pd.read_csv(estabelecimentos_path)\n",
    "estabelecimentos_df = estabelecimentos_df.drop_duplicates(subset=['id'], keep='first')\n",
    "# Ajustar o tipo para \"Feira Livre\" se o 'id' começar com \"FeiraLivre\"\n",
    "estabelecimentos_df.loc[estabelecimentos_df['id'].str.startswith('FeiraLivre', na=False), 'Tipo'] = 'Feira Livre'\n",
    "output_path = \"Estabelecimentos.csv\"\n",
    "estabelecimentos_df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar os pontos fora do contorno de sao paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denil\\AppData\\Local\\Temp\\ipykernel_1164\\1487091325.py:28: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  estabelecimentos_dentro_contorno = estabelecimentos_gdf[estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id                 Rede  \\\n",
      "0  Academia de Ginastica_10.093.874         A! Body Tech   \n",
      "1  Academia de Ginastica_10.156.197  Companhia Athletica   \n",
      "2  Academia de Ginastica_11.093.385  Engenharia do Corpo   \n",
      "3  Academia de Ginastica_11.093.386            Smart Fit   \n",
      "4  Academia de Ginastica_11.093.387              Bluefit   \n",
      "\n",
      "                                            Nome    Localizado em  \\\n",
      "0                            Brooklin Guararapes              Rua   \n",
      "1                                            NaN  Shopping Center   \n",
      "2                   Academia Engenharia do Corpo              Rua   \n",
      "3  Academia Smart Fit Avenida Conselheiro Carrao              Rua   \n",
      "4                                        Bluefit              Rua   \n",
      "\n",
      "                        Endereço                 Bairro                 CEP  \\\n",
      "0               R Guararapes, 20           Alto Da Lapa           04561-000   \n",
      "1  Av Roque Petroni Júnior, 1089  Chácara Santo Antônio  [4707900, 4707970]   \n",
      "2                 Av. Reg. Feijó        Vila Reg. Feijó           03342-001   \n",
      "3         Av. Conselheiro Carrão      Vila Gomes Cardim           03403-000   \n",
      "4                  Alfredo Pujol                Santana           02017-011   \n",
      "\n",
      "                    Tipo   Latitude  Longitude                     geometry  \n",
      "0  Academia de Ginastica -23.522665 -46.704165  POINT (-46.70416 -23.52266)  \n",
      "1  Academia de Ginastica -23.623109 -46.698569  POINT (-46.69857 -23.62311)  \n",
      "2  Academia de Ginastica -23.558981 -46.568930  POINT (-46.56893 -23.55898)  \n",
      "3  Academia de Ginastica -23.549771 -46.545412  POINT (-46.54541 -23.54977)  \n",
      "4  Academia de Ginastica -23.500255 -46.634622  POINT (-46.63462 -23.50026)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from Search.Search_Archives import encontrar_arquivo\n",
    "from Search.Search_Diretory import encontrar_diretorio\n",
    "\n",
    "# Caminho para o arquivo de estabelecimentos corrigidos\n",
    "estabelecimentos_path = encontrar_arquivo('estabelecimentos_dentro_contorno_atualizado.csv')\n",
    "estabelecimentos = pd.read_csv(estabelecimentos_path)\n",
    "\n",
    "# Caminho para o arquivo do contorno de São Paulo\n",
    "path = encontrar_diretorio(\"distritos_quadras\")\n",
    "arquivo_geojson = os.path.join(path, \"sao_paulo_contorno.geojson\")\n",
    "\n",
    "# Carregar o contorno de São Paulo\n",
    "sp_contorno = gpd.read_file(arquivo_geojson)\n",
    "\n",
    "# Converter os estabelecimentos em um GeoDataFrame\n",
    "estabelecimentos_gdf = gpd.GeoDataFrame(\n",
    "    estabelecimentos,\n",
    "    geometry=gpd.points_from_xy(estabelecimentos.Longitude, estabelecimentos.Latitude),\n",
    "    crs=sp_contorno.crs\n",
    ")\n",
    "\n",
    "# Filtrar os estabelecimentos dentro do contorno de São Paulo\n",
    "estabelecimentos_dentro_contorno = estabelecimentos_gdf[estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n",
    "\n",
    "# Exibir ou salvar o resultado\n",
    "print(estabelecimentos_dentro_contorno.head())\n",
    "\n",
    "# Opcional: salvar em um arquivo CSV\n",
    "#estabelecimentos_dentro_contorno.to_csv('estabelecimentos_dentro_contorno.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionar pontos restantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Adicionar o caminho ao sistema para importar funções necessárias\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from Search.Search_Archives import encontrar_arquivo\n",
    "\n",
    "# Carregar os arquivos necessários\n",
    "estabelecimentos_path = encontrar_arquivo('Estabelecimentos.csv')\n",
    "dentro_contorno_path = encontrar_arquivo('estabelecimentos_dentro_contorno.csv')\n",
    "bairros_path = encontrar_arquivo('bairros.xlsx')\n",
    "\n",
    "# Ler os arquivos\n",
    "estabelecimentos_df = pd.read_csv(estabelecimentos_path)\n",
    "dentro_contorno_df = pd.read_csv(dentro_contorno_path)\n",
    "bairros_df = pd.read_excel(bairros_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os CEPs\n",
    "def tratar_cep(cep):\n",
    "    if pd.isna(cep):\n",
    "        return None\n",
    "    cep_str = str(cep).replace(\"-\", \"\").strip()  # Remover traços e espaços\n",
    "    if \",\" in cep_str:\n",
    "        cep_str = cep_str.split(\",\")[0]  # Considerar o primeiro CEP em caso de múltiplos\n",
    "    return cep_str\n",
    "\n",
    "# Aplicar normalização aos DataFrames\n",
    "estabelecimentos_df['CEP'] = estabelecimentos_df['CEP'].apply(tratar_cep)\n",
    "bairros_df['CEP'] = bairros_df['CEP'].apply(tratar_cep)\n",
    "\n",
    "# Identificar os IDs de estabelecimentos que não estão dentro do contorno\n",
    "ids_nao_contidos = estabelecimentos_df[~estabelecimentos_df['id'].isin(dentro_contorno_df['id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mesclar com o DataFrame de bairros para adicionar latitude e longitude com base no CEP\n",
    "ids_nao_contidos = ids_nao_contidos.drop(columns=['Latitude', 'Longitude'], errors='ignore')  # Remover as colunas existentes\n",
    "ids_nao_contidos = ids_nao_contidos.merge(\n",
    "    bairros_df[['CEP', 'Longitude', 'Latitude']],\n",
    "    on='CEP',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas as colunas desejadas\n",
    "ids_nao_contidos = ids_nao_contidos[\n",
    "    ['id', 'Rede', 'Nome', 'Localizado em', 'Endereço', 'Bairro', 'CEP', 'Tipo', 'Latitude', 'Longitude']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas desnecessárias de dentro_contorno_df para combinar os dois conjuntos\n",
    "dentro_contorno_df = dentro_contorno_df[\n",
    "    ['id', 'Rede', 'Nome', 'Localizado em', 'Endereço', 'Bairro', 'CEP', 'Tipo', 'Latitude', 'Longitude']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo atualizado salvo em: estabelecimentos_dentro_contorno_atualizado.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combinar os DataFrames\n",
    "atualizado_df = pd.concat([dentro_contorno_df, ids_nao_contidos], ignore_index=True)\n",
    "\n",
    "# Salvar o arquivo final\n",
    "output_path = \"estabelecimentos_dentro_contorno_atualizado.csv\"\n",
    "atualizado_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Arquivo atualizado salvo em: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar se os estabelecimentos tem seu CEP correspondente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# Ler os arquivos\n",
    "estabelecimentos_df = pd.read_csv('estabelecimentos_dentro_contorno_atualizado.csv')\n",
    "bairros_df = pd.read_excel('bairros.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os CEPs\n",
    "def tratar_cep(cep):\n",
    "    if pd.isna(cep):\n",
    "        return None\n",
    "    # Converter para string e remover todos os caracteres que não são números\n",
    "    cep_str = re.sub(r'\\D', '', str(cep))  # \\D corresponde a qualquer caractere que não seja um dígito\n",
    "    if \",\" in cep_str:\n",
    "        cep_str = cep_str.split(\",\")[0]  # Considerar o primeiro CEP em caso de múltiplos\n",
    "    return cep_str\n",
    "\n",
    "# Aplicar normalização aos DataFrames\n",
    "estabelecimentos_df['CEP'] = estabelecimentos_df['CEP'].apply(tratar_cep)\n",
    "bairros_df['CEP'] = bairros_df['CEP'].apply(tratar_cep)\n",
    "\n",
    "# Filtrar apenas os estabelecimentos do tipo \"Farmácia\"\n",
    "farmacias_df = estabelecimentos_df[estabelecimentos_df['Tipo'].str.lower() == \"farmacia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2138020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3568000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1120010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3119010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8240095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8485580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5271000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CEP\n",
       "0  2138020\n",
       "1  3568000\n",
       "2  1120010\n",
       "3  3119010\n",
       "4  2976000\n",
       "5  8240095\n",
       "6  2633000\n",
       "7  8485580\n",
       "8  5271000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar correspondência de CEPs\n",
    "def verificar_cep_correspondente(farmacias_df, bairros_df):\n",
    "    # Merge entre os DataFrames para encontrar correspondências de CEP\n",
    "    correspondencias = pd.merge(farmacias_df, bairros_df, on='CEP', how='inner')\n",
    "    return correspondencias[['CEP']].drop_duplicates()  # Retorna apenas os CEPs correspondentes, removendo duplicados\n",
    "\n",
    "# Obter as correspondências\n",
    "correspondencias_df = verificar_cep_correspondente(farmacias_df, bairros_df)\n",
    "correspondencias_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter as coordenadas finais de latitude e de longitude restantes com api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro na solicitação para o endereço Rua Dona Antônia De Queirós 333 Faculdade Instituto De Pesquisa E Educação Em Saúde De São Paulo - Fipessp Consolação São Paulo: 422 Client Error: Unknown for url: https://api.mapbox.com/geocoding/v5/mapbox.places/Rua%20Dona%20Ant%C3%B4nia%20De%20Queir%C3%B3s%20333%20Faculdade%20Instituto%20De%20Pesquisa%20E%20Educa%C3%A7%C3%A3o%20Em%20Sa%C3%BAde%20De%20S%C3%A3o%20Paulo%20-%20Fipessp%20Consola%C3%A7%C3%A3o%20S%C3%A3o%20Paulo.json?access_token=pk.eyJ1IjoicHJvamV0b2RhZG9zIiwiYSI6ImNtMXdiNjVobTBpa2Eya3BsMnR5OWxsd3AifQ.SGh5qTES1kmMN3VNFzZAwQ&proximity=-46.63389,-23.55028\n",
      "Processo concluído e dados salvos em 'estabelecimentos_dentro_contorno_atualizado.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Carregar o arquivo existente com dados parciais\n",
    "file_name = \"estabelecimentos_dentro_contorno_atualizado.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# Token e endpoint do Mapbox\n",
    "token = \"pk.eyJ1IjoicHJvamV0b2RhZG9zIiwiYSI6ImNtMXdiNjVobTBpa2Eya3BsMnR5OWxsd3AifQ.SGh5qTES1kmMN3VNFzZAwQ\"\n",
    "SAO_PAULO = (-46.63389, -23.55028)\n",
    "\n",
    "# Loop para obter coordenadas de cada endereço apenas para as linhas que estão sem Latitude e Longitude\n",
    "count = 0\n",
    "for i, row in df.iterrows():\n",
    "    # Verifica se a latitude e longitude já estão preenchidas\n",
    "    if pd.notna(row['Latitude']) and pd.notna(row['Longitude']):\n",
    "        continue  # Pula esta linha se as coordenadas já estão presentes\n",
    "\n",
    "    # Monta o texto de busca e a URL para a API\n",
    "    search_text = f\"{row['Endereço']} {row['Bairro']} São Paulo\"\n",
    "    url = f\"https://api.mapbox.com/geocoding/v5/mapbox.places/{search_text}.json?access_token={token}&proximity={SAO_PAULO[0]},{SAO_PAULO[1]}\"\n",
    "\n",
    "    try:\n",
    "        # Faz a solicitação à API\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Lança um erro se a resposta não for bem-sucedida\n",
    "        data = response.json()\n",
    "\n",
    "        # Verifica se há dados nas features\n",
    "        if not data.get(\"features\"):\n",
    "            print(f\"Nenhum resultado para o endereço: {search_text}\")\n",
    "            continue\n",
    "\n",
    "        # Atualiza o DataFrame com a nova Latitude e Longitude\n",
    "        df.at[i, \"Latitude\"] = data[\"features\"][0][\"geometry\"][\"coordinates\"][1]\n",
    "        df.at[i, \"Longitude\"] = data[\"features\"][0][\"geometry\"][\"coordinates\"][0]\n",
    "\n",
    "        # Incrementa o contador e exibe o progresso a cada 100 registros\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print(f\"{count} registros processados\")\n",
    "\n",
    "        # Salva o progresso a cada 1000 linhas processadas\n",
    "        if count % 1000 == 0:\n",
    "            df.to_csv(file_name, index=False)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erro na solicitação para o endereço {search_text}: {e}\")\n",
    "\n",
    "# Salva o arquivo final após processar todas as linhas\n",
    "df.to_csv(file_name, index=False)\n",
    "print(f\"Processo concluído e dados salvos em '{file_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificar pontos que ainda estao fora do contorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denil\\AppData\\Local\\Temp\\ipykernel_13480\\1818941439.py:30: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  estabelecimentos_dentro_contorno = estabelecimentos_gdf[estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n",
      "C:\\Users\\Denil\\AppData\\Local\\Temp\\ipykernel_13480\\1818941439.py:33: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  estabelecimentos_fora_contorno = estabelecimentos_gdf[~estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de estabelecimentos fora do contorno de São Paulo: 561\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Adicionar o caminho ao sistema para importar funções necessárias\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from Search.Search_Archives import encontrar_arquivo\n",
    "from Search.Search_Diretory import encontrar_diretorio\n",
    "\n",
    "# Caminho para o arquivo de estabelecimentos corrigidos\n",
    "estabelecimentos_path = encontrar_arquivo('estabelecimentos_dentro_contorno.csv')\n",
    "estabelecimentos = pd.read_csv(estabelecimentos_path)\n",
    "\n",
    "# Caminho para o arquivo do contorno de São Paulo\n",
    "path = encontrar_diretorio(\"distritos_quadras\")\n",
    "arquivo_geojson = os.path.join(path, \"sao_paulo_contorno.geojson\")\n",
    "\n",
    "# Carregar o contorno de São Paulo\n",
    "sp_contorno = gpd.read_file(arquivo_geojson)\n",
    "\n",
    "# Converter os estabelecimentos em um GeoDataFrame\n",
    "estabelecimentos_gdf = gpd.GeoDataFrame(\n",
    "    estabelecimentos,\n",
    "    geometry=gpd.points_from_xy(estabelecimentos.Longitude, estabelecimentos.Latitude),\n",
    "    crs=sp_contorno.crs\n",
    ")\n",
    "\n",
    "# Filtrar os estabelecimentos dentro do contorno de São Paulo\n",
    "estabelecimentos_dentro_contorno = estabelecimentos_gdf[estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n",
    "\n",
    "# Filtrar os estabelecimentos fora do contorno de São Paulo\n",
    "estabelecimentos_fora_contorno = estabelecimentos_gdf[~estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n",
    "\n",
    "# Contar os estabelecimentos fora do contorno\n",
    "quantidade_fora_contorno = len(estabelecimentos_fora_contorno)\n",
    "\n",
    "# Exibir a quantidade\n",
    "print(f\"Quantidade de estabelecimentos fora do contorno de São Paulo: {quantidade_fora_contorno}\")\n",
    "\n",
    "# Opcional: salvar os resultados em arquivos CSV\n",
    "estabelecimentos_dentro_contorno.to_csv('estabelecimentos_dentro_contorno.csv', index=False)\n",
    "estabelecimentos_fora_contorno.to_csv('estabelecimentos_fora_contorno.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estabelecimentos_fora_contorno.to_csv('estabelecimentos_fora_contorno.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter CEP com geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denil\\AppData\\Local\\Temp\\ipykernel_1164\\1950055838.py:47: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  estabelecimentos_fora_contorno = estabelecimentos_gdf[~estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo atualizado e salvo em: c:\\Users\\Denil\\OneDrive\\Documentos\\GitHub\\PROJETO_NORTIS\\streamlit_app\\data\\companies\\estabelecimentos_dentro_contorno_atualizado.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import sys\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "# Adicionar o caminho ao sistema para importar funções necessárias\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "from Search.Search_Archives import encontrar_arquivo\n",
    "from Search.Search_Diretory import encontrar_diretorio\n",
    "\n",
    "# Configurar o geocodificador Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geopy_locator\")\n",
    "\n",
    "# Função para obter coordenadas corrigidas\n",
    "def obter_coordenadas(endereco):\n",
    "    try:\n",
    "        location = geolocator.geocode(endereco, timeout=10)\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao buscar coordenadas para o endereço {endereco}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Caminho para o arquivo de estabelecimentos corrigidos\n",
    "estabelecimentos_path = encontrar_arquivo('estabelecimentos_dentro_contorno_atualizado.csv')\n",
    "estabelecimentos = pd.read_csv(estabelecimentos_path)\n",
    "\n",
    "# Caminho para o arquivo do contorno de São Paulo\n",
    "path = encontrar_diretorio(\"distritos_quadras\")\n",
    "arquivo_geojson = os.path.join(path, \"sao_paulo_contorno.geojson\")\n",
    "\n",
    "# Carregar o contorno de São Paulo\n",
    "sp_contorno = gpd.read_file(arquivo_geojson)\n",
    "\n",
    "# Converter os estabelecimentos em um GeoDataFrame\n",
    "estabelecimentos_gdf = gpd.GeoDataFrame(\n",
    "    estabelecimentos,\n",
    "    geometry=gpd.points_from_xy(estabelecimentos.Longitude, estabelecimentos.Latitude),\n",
    "    crs=sp_contorno.crs\n",
    ")\n",
    "\n",
    "# Filtrar os estabelecimentos fora do contorno de São Paulo\n",
    "estabelecimentos_fora_contorno = estabelecimentos_gdf[~estabelecimentos_gdf.geometry.within(sp_contorno.unary_union)]\n",
    "\n",
    "# Recalcular coordenadas para os estabelecimentos fora do contorno\n",
    "for index, row in estabelecimentos_fora_contorno.iterrows():\n",
    "    endereco = f\"{row['Endereço']} {row['Bairro']} {row['CEP']} São Paulo, Brazil\"\n",
    "    nova_latitude, nova_longitude = obter_coordenadas(endereco)\n",
    "\n",
    "    # Atualizar somente se novas coordenadas forem válidas\n",
    "    if nova_latitude is not None and nova_longitude is not None:\n",
    "        estabelecimentos.at[index, \"Latitude\"] = nova_latitude\n",
    "        estabelecimentos.at[index, \"Longitude\"] = nova_longitude\n",
    "\n",
    "    # Adicione um delay para evitar exceder limites de requisições\n",
    "    time.sleep(1)\n",
    "\n",
    "# Salvar o arquivo corrigido\n",
    "estabelecimentos.to_csv(estabelecimentos_path, index=False)\n",
    "print(f\"Arquivo atualizado e salvo em: {estabelecimentos_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
